quarkus.http.port=4315

# Langchain4j
quarkus.langchain4j.chat-model.provider=ollama
quarkus.langchain4j.chat-memory.memory-window.max-messages=20

# OpenAI
quarkus.langchain4j.openai.enable-integration=false
quarkus.langchain4j.openai.timeout=120s


#Ollama
quarkus.langchain4j.ollama.enable-integration=true
quarkus.langchain4j.ollama.chat-model.model-id=codellama
quarkus.langchain4j.ollama.timeout=120s
quarkus.langchain4j.ollama.chat-model.format=json

quarkus.banner.path=asciiart.txt
quarkus.langchain4j.log-requests=false
quarkus.langchain4j.log-responses=false
quarkus.langchain4j.timeout=120s
